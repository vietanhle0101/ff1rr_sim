{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from matplotlib import pyplot as plt\n",
    "import GPy\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\vl385\\Documents\\casadi-windows-py37-v3.5.1\")\n",
    "from casadi import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linGP:\n",
    "    def __init__(self, model):\n",
    "        # Initialize by GPy model or by dictionary containing all information\n",
    "        if type(model) == GPy.models.gp_regression.GPRegression:\n",
    "            self.rbf_variance = model.rbf.variance.values[0]\n",
    "            self.rbf_lengthscale = model.rbf.lengthscale.values\n",
    "            self.noise_variance = model.Gaussian_noise.variance.values[0]\n",
    "            self.X = np.array(model.X)\n",
    "            self.Y = model.Y\n",
    "        elif type(model) == dict:\n",
    "            self.rbf_variance = model[\"rbf_variance\"]\n",
    "            self.rbf_lengthscale = model[\"rbf_lengthscale\"]\n",
    "            self.noise_variance = model[\"noise_variance\"]\n",
    "            self.X = model[\"X_train\"]\n",
    "            self.Y = model[\"Y_train\"]  \n",
    "            \n",
    "        self.N = len(self.Y)\n",
    "        self.n = np.shape(self.X)[1]\n",
    "        self.lambda_inv = np.diag(1/self.rbf_lengthscale**2)\n",
    "        \n",
    "        x = SX.sym('x', self.n, 1)\n",
    "        y = SX.sym('y', self.n, 1)\n",
    "        k_xy = self.rbf_variance**2*exp(-0.5*mtimes([(x-y).T, self.lambda_inv, (x-y)]))\n",
    "        self.k = Function('k', [x, y], [k_xy])\n",
    "        k10_xy = gradient(k_xy, x) \n",
    "        self.k10 = Function('k10', [x, y], [k10_xy])\n",
    "        k01_xy = jacobian(k_xy, y)\n",
    "        self.k01 = Function('k01', [x, y], [k01_xy])\n",
    "        k11_xy = jacobian(k10_xy, y)\n",
    "        self.k11 = Function('k11', [x, y], [k11_xy])\n",
    "        \n",
    "        self.Sigma_inverse()\n",
    "        \n",
    "    def Sigma_inverse(self):\n",
    "        # Pre-compute (K_N + sigma^2*I)^-1 and (K_N + sigma^2*I)^-1*Y\n",
    "        K_N = np.empty((self.N, self.N))\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                K_N[i,j] = self.se_kernel(self.X[i,:], self.X[j,:])\n",
    "        self.Sigma_inv = LA.inv(K_N + self.noise_variance**2*np.eye(self.N))\n",
    "        self.alpha = np.dot(self.Sigma_inv, self.Y)\n",
    "    \n",
    "    def se_kernel(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k(x, y)\n",
    "        \n",
    "    def se_kernel_01(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k01(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k01(x, y)\n",
    "                \n",
    "    def se_kernel_10(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k10(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k10(x, y)\n",
    "        \n",
    "    def se_kernel_11(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k11(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k11(x, y)\n",
    "                \n",
    "    def predict(self, p):\n",
    "        if type(p) == casadi.SX:\n",
    "            K_star = self.se_kernel(p, p)\n",
    "            K_xN = self.k.map(self.N) \n",
    "            K_star_N = K_xN(p, self.X.transpose())\n",
    "            K_N_star = K_star_N.T \n",
    "            mean = mtimes([K_star_N, self.alpha])\n",
    "            variance = K_star - mtimes([K_star_N, self.Sigma_inv, K_N_star]) + self.noise_variance**2         \n",
    "        \n",
    "        elif type(p) == np.ndarray:\n",
    "            K_star = self.se_kernel(p, p)\n",
    "            K_xN = self.k.map(self.N) \n",
    "            K_star_N = K_xN(p, self.X.transpose()).full()\n",
    "            K_N_star = K_star_N.transpose()  \n",
    "            mean = LA.multi_dot([K_star_N, self.alpha])\n",
    "            variance = K_star - LA.multi_dot([K_star_N, self.Sigma_inv, K_N_star]) \\\n",
    "                + self.noise_variance**2\n",
    "\n",
    "        return mean, variance\n",
    "    \n",
    "    def linearize(self, p, use_var = False):\n",
    "        if type(p) == np.ndarray:\n",
    "            K_xN = self.k.map(self.N) \n",
    "            K_star_N = K_xN(p, self.X.transpose())\n",
    "            K10_xN = self.k10.map(self.N)\n",
    "            K10_star_N = K10_xN(p, self.X.transpose())\n",
    "\n",
    "            A = np.vstack([K_star_N, K10_star_N])\n",
    "            mx = np.dot(A, self.alpha)\n",
    "            if use_var: \n",
    "                K_star = self.se_kernel(p, p)\n",
    "                K01_star = self.se_kernel_01(p, p)\n",
    "                K10_star = self.se_kernel_10(p, p)\n",
    "                K11_star = self.se_kernel_11(p, p)\n",
    "\n",
    "                B = np.vstack([np.hstack([K_star, K01_star]), np.hstack([K10_star, K11_star])])\n",
    "                C = LA.multi_dot([A, self.Sigma_inv, A.T])\n",
    "                Vx = B-C            \n",
    "                return mx, Vx\n",
    "            else: return mx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dict = pickle.load(open(\"GP_dx.pkl\", \"rb\"))\n",
    "gp = linGP(m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29028366],\n",
       "       [0.29851104],\n",
       "       [0.04634795],\n",
       "       [0.16867219],\n",
       "       [0.09112418]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = gp.X[0,:]\n",
    "gp.linearize(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.33036026]]), array([[3.76846961e-07]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.predict(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearized Sparse GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linsparse_GP:\n",
    "    def __init__(self, model):\n",
    "        # Initialize by GPy model or by dictionary containing all information\n",
    "        if type(model) == GPy.models.sparse_gp_regression.SparseGPRegression:\n",
    "            self.rbf_variance = model.rbf.variance.values[0]\n",
    "            self.rbf_lengthscale = model.rbf.lengthscale.values\n",
    "            self.noise_variance = model.Gaussian_noise.variance.values[0]\n",
    "            self.X = np.array(model.X)\n",
    "            self.Y = model.Y\n",
    "            self.Z = model.inducing_inputs.values\n",
    "        elif type(model) == dict:\n",
    "            self.rbf_variance = model[\"rbf_variance\"]\n",
    "            self.rbf_lengthscale = model[\"rbf_lengthscale\"]\n",
    "            self.noise_variance = model[\"noise_variance\"]\n",
    "            self.X = model[\"X_train\"]\n",
    "            self.Y = model[\"Y_train\"]\n",
    "            self.Z = model[\"X_ind\"]\n",
    "            \n",
    "        self.N = len(self.Y)\n",
    "        self.N_ind = len(self.Z)\n",
    "        self.n = np.shape(self.X)[1]\n",
    "        self.lambda_inv = np.diag(1/self.rbf_lengthscale**2)\n",
    "        \n",
    "        x = SX.sym('x', self.n, 1)\n",
    "        y = SX.sym('y', self.n, 1)\n",
    "        k_xy = self.rbf_variance**2*exp(-0.5*mtimes([(x-y).T, self.lambda_inv, (x-y)]))\n",
    "        self.k = Function('k', [x, y], [k_xy])\n",
    "        k10_xy = gradient(k_xy, x) \n",
    "        self.k10 = Function('k10', [x, y], [k10_xy])\n",
    "        k01_xy = jacobian(k_xy, y)\n",
    "        self.k01 = Function('k01', [x, y], [k01_xy])\n",
    "        k11_xy = jacobian(k10_xy, y)\n",
    "        self.k11 = Function('k11', [x, y], [k11_xy])\n",
    "        \n",
    "        self.Sigma_inverse()\n",
    "        \n",
    "        \n",
    "    def Sigma_inverse(self):\n",
    "        # Pre-compute (K_N + sigma^2*I)^-1        \n",
    "        self.K_NZ = np.empty((self.N, self.N_ind)) \n",
    "        self.K_ZZ = np.empty((self.N_ind, self.N_ind))  \n",
    "        K_NN = np.empty((self.N, self.N))\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N_ind):\n",
    "                self.K_NZ[i,j] = self.se_kernel(self.X[i,:], self.Z[j,:])\n",
    "        for i in range(self.N_ind):\n",
    "            for j in range(self.N_ind):\n",
    "                self.K_ZZ[i,j] = self.se_kernel(self.Z[i,:], self.Z[j,:])\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                K_NN[i,j] = self.se_kernel(self.X[i,:], self.X[j,:])\n",
    "           \n",
    "        self.K_ZN = self.K_NZ.transpose()\n",
    "        Q_NN = LA.multi_dot([self.K_NZ, LA.inv(self.K_ZZ), self.K_ZN])\n",
    "        LAMBDA = np.diag(np.diag(K_NN - Q_NN + self.noise_variance**2*np.eye(self.N)))\n",
    "        self.Sigma_inv = LA.inv(Q_NN + LAMBDA)\n",
    "        self.alpha = LA.multi_dot([LA.inv(self.K_ZZ), self.K_ZN, self.Sigma_inv, self.Y]) \n",
    "        self.beta = LA.multi_dot([LA.inv(self.K_ZZ), self.K_ZN, self.Sigma_inv, \\\n",
    "                                  self.K_ZN.transpose(), LA.inv(self.K_ZZ).transpose()]) \n",
    "    \n",
    "    def se_kernel(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k(x, y)\n",
    "        \n",
    "    def se_kernel_01(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k01(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k01(x, y)\n",
    "                \n",
    "    def se_kernel_10(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k10(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k10(x, y)\n",
    "        \n",
    "    def se_kernel_11(self, x, y):\n",
    "        if type(x) == np.ndarray and type(y) == np.ndarray:\n",
    "            return self.k11(x, y).full()\n",
    "        elif type(x) == casadi.SX or type(y) == casadi.SX:\n",
    "            return self.k11(x, y)\n",
    "                \n",
    "    def predict(self, p):\n",
    "        if type(p) == casadi.SX:\n",
    "            K_xN = self.k.map(self.N_ind) \n",
    "            K_star_Z = K_xN(p, self.Z.transpose())\n",
    "            mean = mtimes(K_star_Z, self.alpha)\n",
    "            K_star = self.se_kernel(p, p)\n",
    "            K_Z_star = K_star_Z.T\n",
    "            variance = K_star - mtimes([K_star_Z, self.beta, K_Z_star]) \\\n",
    "                + self.noise_variance**2       \n",
    "        \n",
    "        elif type(p) == np.ndarray:\n",
    "            K_xN = self.k.map(self.N_ind) \n",
    "            K_star_Z = K_xN(p, self.Z.transpose()).full()\n",
    "            mean = np.dot(K_star_Z, self.alpha)\n",
    "            K_star = self.se_kernel(p, p)\n",
    "            K_Z_star = K_star_Z.transpose()\n",
    "            \n",
    "            variance = K_star - LA.multi_dot([K_star_Z, self.beta, K_Z_star]) \\\n",
    "                + self.noise_variance**2\n",
    "\n",
    "        return mean, variance\n",
    "    \n",
    "    def linearize(self, p, use_var = False):\n",
    "        if type(p) == np.ndarray:\n",
    "            K_xN = self.k.map(self.N_ind) \n",
    "            K_star_Z = K_xN(p, self.Z.transpose())\n",
    "            K10_xN = self.k10.map(self.N_ind) \n",
    "            K10_star_Z = K10_xN(p, self.Z.transpose())\n",
    "            A = np.vstack([K_star_Z, K10_star_Z])\n",
    "            mx = np.dot(A, self.alpha)\n",
    "            if use_var: \n",
    "                K_star = self.se_kernel(p, p)\n",
    "                K01_star = self.se_kernel_01(p, p)\n",
    "                K10_star = self.se_kernel_10(p, p)\n",
    "                K11_star = self.se_kernel_11(p, p)\n",
    "\n",
    "                B = np.vstack([np.hstack([K_star, K01_star]), np.hstack([K10_star, K11_star])])\n",
    "                C = LA.multi_dot([A, self.beta, A.T])\n",
    "                Vx = B-C            \n",
    "                return mx, Vx\n",
    "            else: return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29450164],\n",
       "       [ 0.25689588],\n",
       "       [-0.00037243],\n",
       "       [ 0.1426474 ],\n",
       "       [-0.12452423]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_dict = pickle.load(open(\"sparse_dx.pkl\", \"rb\"))\n",
    "sparsegp = linsparse_GP(m_dict)\n",
    "p = gp.X[0,:]\n",
    "sparsegp.linearize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.99999803e-01,  6.26999959e-04,  1.49773600e+00, -2.10420000e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4286a6e2abad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start with an empty NLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlbx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mubx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mlbg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mubg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inf' is not defined"
     ]
    }
   ],
   "source": [
    "# Start with an empty NLP\n",
    "lbx = [-3,-3]\n",
    "ubx = [12, inf]\n",
    "g = []; lbg = []; ubg = []\n",
    "\n",
    "x = SX.sym('x'); y = SX.sym('y')\n",
    "p = SX.sym('p')\n",
    "g += [x-2*y]\n",
    "g += [x+y]\n",
    "lbg += [-10, -8]\n",
    "ubg += [8, 12]\n",
    "qp = {'x':vertcat(x,y), 'p': p, 'f':x**2-p*x+y**2, 'g': vertcat(*g)}\n",
    "S = qpsol('S', 'qpoases', qp, {'printLevel':'none'})\n",
    "print(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_opt:  [0.5, -5.55112e-017]\n"
     ]
    }
   ],
   "source": [
    "sol = S(lbg = lbg, ubg = ubg, lbx=lbx, ubx = ubx, p = 1)\n",
    "x_opt = sol['x']\n",
    "print('x_opt: ', x_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-1fac3d201c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'car' is not defined"
     ]
    }
   ],
   "source": [
    "car.ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
